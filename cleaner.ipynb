{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Data Exploration and Cleaning --\n",
    "Cleaner for project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in the csv file\n",
    "df = pd.read_csv(\"data/default_of_credit_card_clients__courseware_version_1_21_19.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration Phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps 1 and 2 How many rows and columns?\n",
    "# use .shape method to find out\n",
    "# 30000 rows and 25 columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 What kind of features are there in the data?\n",
    "# use .info to figure out the data types of each\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is mostly numerical except for whether the account defaulted \n",
    "# that last column is categorical\n",
    "# check one last time useing.head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 finding the frequncy of features(columns) in the data frame \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists all columns of the data frame \n",
    "# Account ID column is referenced as ID \n",
    "# Remaining columns are out features\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all unique values of ID  in the df\n",
    "# since there are 30000 rows there should be 30000 unique columns\n",
    "df['ID'].nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't know if they are the same duplicated values or different\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_counts = df['ID'].value_counts() # shows all different values that are duplicates\n",
    "id_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displays the number of grouped entries \n",
    "# 29374 are repeated once \n",
    "# 313 are repeated twice\n",
    "id_counts.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to make Boolean masks(used to filter an array or series using a condition in Python: ==, >)\n",
    "# We will do this by having the indices of the id_counts series \n",
    "# to locate duplicates where the count is 2\n",
    "\n",
    "dupe_mask = id_counts == 2 \n",
    "dupe_mask[0:5] # displays the id and the boolean value they hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use logical masks to select IDs that are duplicated \n",
    "# ids themselves are contained as the index of the id_count series \n",
    "id_counts.index[0:5] # accesses index id_count and displays first five rows as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_ids = id_counts.index[dupe_mask]\n",
    "dupe_ids = list(dupe_ids)\n",
    "len(dupe_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_ids[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ID'].isin(dupe_ids[0:5]), :].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a boolean matrix of the size of the data frame \n",
    "df_zero_mask = df == 0\n",
    "# df_zero_mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \n",
    "feature_zero_mask = df_zero_mask.iloc[:, 1:].all(axis=1)\n",
    "# feature_zero_mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data frame, where there are duplicates/ drop the duplicates \n",
    "df_clean_1 = df.loc[~feature_zero_mask,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_1['ID'].nunique() # number of unique IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_1 = df_clean_1[(df.T != 0).any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 5 : Exploring and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_1['PAY_1'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_1['PAY_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a logical mask with != to find all rows that don't \n",
    "# missing data for the PAY_1 feature\n",
    "# valid_pay_1_mask is a pandas series of boolean values\n",
    "valid_pay_1_mask = df_clean_1['PAY_1'] != 'Not available'\n",
    "valid_pay_1_mask[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(valid_pay_1_mask[0])\n",
    "type(valid_pay_1_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will check to see how many rows have no missing data\n",
    "# by calculating the sum of the mask\n",
    "sum(valid_pay_1_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data by eliminating the rows with missing values of PAY_1\n",
    "# Series.loc access a group of values using labels\n",
    "df_clean_2 = df_clean_1.loc[valid_pay_1_mask,:].copy()\n",
    "df_clean_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_2['PAY_1'] = df_clean_2['PAY_1'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_2[['PAY_1', 'PAY_2']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_2.to_csv('data/default_of_clients_cleaned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
